{"batch_size": 4, "epochs": 10, "l1_dropout": 0.0, "l1_reg": 0.008474614931033098, "l2_dropout": 0.0, "l2_reg": 0.00011299781626939068, "layers": 2, "learning_rate": 0.009127013888274143, "n_neurons_l1": 2, "n_neurons_l2": 8}